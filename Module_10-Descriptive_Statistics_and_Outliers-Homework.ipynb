{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a912cedd",
   "metadata": {},
   "source": [
    "# Module 10: Descriptive Statistics and Outliers\n",
    "***\n",
    "\n",
    "## What are statistics?\n",
    "\n",
    "Statistics deal with collecting informative data, interpreting these data, and drawing conclusions about the data. Statistics are used across multiple disciplines and fuel business and policy decisions.\n",
    "\n",
    "## Two types of statistics\n",
    "***\n",
    "#### Descriptive Statistics\n",
    "Descriptive statistics use numeric and graphical techniques to summarize the characteristics of a set of data and to identify patterns within the dataset. Descriptive statistics also include graphically summarizing data and presenting the information in a meaningful (easy to interpret) way. \n",
    "\n",
    "#### Inferential Statistics\n",
    "Inferential statistics use samples of data to make generalizations about a larger set of data (or a larger population). Inferential statistics use data to make estimates, decisions, and predictions about patterns and trends identified within a set of data. Inferential statistics are used to make conclusions beyond your immediate set of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e11e6c",
   "metadata": {},
   "source": [
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats ## new library alert! ##\n",
    "\n",
    "## SciPy is used for scientific and mathematic computing; it provides functions for stats, \n",
    "# data manipulation, and data visualization\n",
    "\n",
    "df = pd.read_excel(\"axisdata.xlsx\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df32f8",
   "metadata": {},
   "source": [
    "## Qualitative vs Quantitative Data\n",
    "***\n",
    "\n",
    "#### Quantitative Data\n",
    "Data that are recorded on a numeric scale (i.e. age, weight, salary, number of empty seats on a plane, credit score etc). Quantitative variables are also called <b>numeric</b> variables. \n",
    "\n",
    "#### Qualitative Data\n",
    "Data that cannot be measured on a numeric scale (i.e. eye color, type of car, blood type, race etc). These data can only be classified into one group of categories. Qualitative variables are also called <b>categorical</b> variables. Qualitative data also includes text and string data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which variables are qualitative and which variables are quantitative?\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d91d6d",
   "metadata": {},
   "source": [
    "## Describing Qualitative Data\n",
    "***\n",
    "\n",
    "Qualitative data is best summarized by frequency tables. \n",
    "\n",
    "Frequency tables summarize categorical data into a table showing each category, number of observations that fall within each category, and the relative frequency of each category. \n",
    "\n",
    "Relative frequency is the number of specific observations out of the total number of observations, or the percentage of the total sample that fall within a specific group. Both representations of categorical data give insight into how common specific categories are within a set of data. \n",
    "\n",
    "<b>Bar charts</b> are ideal for graphically representing qualitative data as they visually show the frequency of observations across various groups. \n",
    "\n",
    "#### GRAPHIC SHOULD READ N = 150 !!!\n",
    "\n",
    "<img src=\"FreqTable.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e690da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Frequencies \n",
    "\n",
    "df[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16935be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Relative Frequencies \n",
    "\n",
    "df[\"Gender\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf057364",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multi-variable Frequencies \n",
    "\n",
    "pd.crosstab(df[\"Gender\"], df[\"SalesTraining\"], margins=False, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a409e75f",
   "metadata": {},
   "source": [
    "# { Exercise 1 }\n",
    "\n",
    "    1. Import the \"pokemon.csv\" file; name the dataset 'poke'. Preview the first 5 rows. \n",
    "    2. Determine the frequencies of unique pokemon types (variable name: Type 1) in this dataset\n",
    "    3. Determine the relative frequencies of the unique pokemon types (variable name: Type 1) in this dataset\n",
    "    4. Create a crosstabs table that shows the frequency of pokemon stage (variable name: Stage) and legendary status (variable name: Legendary). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77110b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats ## new library alert! ##\n",
    "\n",
    "## SciPy is used for scientific and mathematic computing; it provides functions for stats, \n",
    "# data manipulation, and data visualization\n",
    "\n",
    "poke = pd.read_csv(\"pokemon.csv\")\n",
    "\n",
    "poke.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "poke[\"Type 1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "poke[[\"Type 1\"]].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e07e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(poke[\"Stage\"], poke[\"Legendary\"], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06401fbf",
   "metadata": {},
   "source": [
    "## Describing Quantitative Data\n",
    "\n",
    "There are many more techniques for describing quantitative data compared to qualitative. When summarizing quantitative data, the objective is to get a sense of how the data is clustered and the variation in numeric values. \n",
    "\n",
    "***\n",
    "\n",
    "### Measures of Central Tendency\n",
    "\n",
    "Measures of Central Tendency are estimates of what a \"typical\" value/data point is within your set of data. A measure of central tendency is a number around which an entire sample of data is spread. We can describe this central position using several statistics, including the mean (average), the median, and the mode. \n",
    "\n",
    "Measures of central tendency can be visualized with a frequency distribution (histogram). A frequency distribution is a description of values and how often each value occurs within your dataset. When you graph a frequency distribution a pattern/shape should give insight into which values occured the most/least. \n",
    "\n",
    "<img src=\"NormalDist.jpg\">\n",
    "\n",
    "***\n",
    "\n",
    "#### Mean\n",
    "\n",
    "The mean, which is the most commonly known and used measure of central tendency, is the arithmetic average of a set of numeric values. The mean is calculated by adding all the values together and dividing by the total number of values in the set of values. In specific sets of data, the mean is the central point in the frequency distribution aka the hump. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9875c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the Mean of a column \n",
    "\n",
    "df[\"Hours Worked\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2722e86",
   "metadata": {},
   "source": [
    "#### Median \n",
    "\n",
    "The median is the value which divides the data into two equal parts when the data is arranged from least to greatest. The median will be the middle value if the number of values is odd, otherwise, it will be the average of the two middle values if the number of values is even. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bffb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the Median of a column \n",
    "\n",
    "df[\"Hours Worked\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9f4a9",
   "metadata": {},
   "source": [
    "#### Mode \n",
    "\n",
    "The mode is the value that appears most frequently in a sample of data, or the value that has the highest frequency. It is possible for a set of data to have no mode, and it is possible for a set of data to have multiple modes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62704419",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the Mode of a column \n",
    "\n",
    "df[\"Hours Worked\"].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238561a5",
   "metadata": {},
   "source": [
    "# { Exercise 2 }\n",
    "\n",
    "    1. Using the pokemon dataset ('poke'), calculate the mean attack value (Attack) in the dataset.  \n",
    "    2. Determine the median defense value (Defense). Write a single sentence on what your findings mean. \n",
    "    3. Determine the mode of the speed (Speed) column. Write a single sentence on what your findings mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4279bb85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ef683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd766711",
   "metadata": {},
   "source": [
    "### Data Distribution and Measurement Sensitivity\n",
    "***\n",
    "\n",
    "### Normally distributed data vs. non-normally distributed data\n",
    "\n",
    "Several statistics are suited for data that follows a <b>normal distribution</b>. When visualized, normally distributed data lies in a symmetrical pattern (bell-shape) where the majority of the data surrounds the mean with decreasing amounts evenly distributed to the left and the right. \n",
    "\n",
    "While this is the ideal, real-world data is not always normally distributed. Non-normal distribution is possible and there are several statistics that can still be used with non-normally distributed data. It is important to determine how your data is distributed before you embark on certain statistics. \n",
    "\n",
    "#### Distribution and Measure of Central Tendency\n",
    "\n",
    "The shape of the data helps to determine which measure of central tendency should be reported. Some statistics are very sensitive to non-normal distributions, while others are more resilient. Three of the most common shapes to learn are symmetric, left-skewed, and right-skewed. <b>Skew</b> is simply a measure of the asymmetry of the distribution. <b>In the below images, while not shown, the values are increasing from left to right.</b> \n",
    "\n",
    "#### Symmetric Data\n",
    "* mean, median, and mode are all the same here\n",
    "* no skewness is apparent\n",
    "* the distribution is described as symmetric\n",
    "\n",
    "<img src=\"Symmetrical.jpg\">\n",
    "\n",
    "***\n",
    "\n",
    "#### Left-skewed Data\n",
    "* mean < median\n",
    "* long tail on the left\n",
    "\n",
    "<img src=\"LeftSkew.jpg\">\n",
    "\n",
    "***\n",
    "\n",
    "#### Right-skewed Data\n",
    "* mean > median\n",
    "* long tail on the right\n",
    "\n",
    "<img src=\"RightSkew.jpg\">\n",
    "\n",
    "***\n",
    "\n",
    "### Considerations for Shape\n",
    "\n",
    "When your data is skewed in either direction, you should consider the best measure of central tendency to report. The median is best used when you have skewed data. This is because the median is less affected by extreme values. \n",
    "\n",
    "If your data is skewed, this could be an indication that your data has extreme high or low values that are contributing to the skewness. Later in this lesson, we will talk about how to handle extreme values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58a707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2427e6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7141c9ea",
   "metadata": {},
   "source": [
    "### Measures of Variability (or Spread)\n",
    "\n",
    "Measures of Variability, or spread, describe the amount of dispersion in your data sample. In other words, measures of variability, describe how spread out values are. For example, in a sample of 100 students, the average test score is 75. However, not all students will have gotten a 75 - their scores will be spread out above and below the average, some will be higher and some lower. To describe the spread of our data, we can use several statistics, including range, standard deviation, percentiles, and quartiles.\n",
    "\n",
    "***\n",
    "\n",
    "#### Range\n",
    "\n",
    "The range is the difference between the lowest and highest value in a set of data. For example, if the maximum value is 10 and the minimum value is 2, the range is 8. The larger the range, the larger the difference between the highest and lowest values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e051a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the range of values in a column\n",
    "\n",
    "hrs_range = df['Hours Worked'].max() - df['Hours Worked'].min()\n",
    "\n",
    "print(hrs_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268202ff",
   "metadata": {},
   "source": [
    "#### Standard Deviation (SD)\n",
    "\n",
    "The SD is a measurement of the average distance between each data value and the mean. You can consider SD as a measure of how spread out the data is from the mean. A low SD indicates that the data points are clustered around the mean, while a high SD indicates the data points are spread out over a wider range of values. \n",
    "\n",
    "<img src=\"https://d20khd7ddkh5ls.cloudfront.net/high_low_standard_deviation.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the Standard Deviation of values in a column\n",
    "\n",
    "print(\"Mean hours worked by all employees:\", df[\"Hours Worked\"].mean())\n",
    "\n",
    "df[\"Hours Worked\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd0c97b",
   "metadata": {},
   "source": [
    "#### Percentiles\n",
    "\n",
    "Percentiles give insight into the relation of one data point to other data points within the same dataset. When the data values are arranged from lowest to highest, percentiles represent the position of a value within the list of values. For example, if a value is at the 50th percentile - 50% of the data falls below the value, and 50% fall above the value. If a value is at the 85th percentile - 85% of the data falls below the value, and 15% fall above the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f15bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate percentiles of values in a column\n",
    "## To determine the value that falls at a specific percentile\n",
    "## np.percentile(data/column, percentile value)\n",
    "\n",
    "np.percentile(df['Hours Worked'], 85)\n",
    "\n",
    "## Determine which value falls at the 85th percentile? \n",
    "## 85% of the values in Hours Worked are below this value, 15% are above this value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b48bb",
   "metadata": {},
   "source": [
    "#### Quartiles \n",
    "\n",
    "Quartiles are values that divide a set of data into equal quarters (when the data is ordered from lowest to highest). There are <b>three</b> quartile values that divide the data into four parts (see below). \n",
    "\n",
    "<img src=\"quar.png\">\n",
    "\n",
    "* The first quartile (Q1) is at the 25th percentile (25% below, 75% above)\n",
    "* The second quartile (Q2) is at the 50th percentile (50% below, 50% above, median)\n",
    "* The third quartile (Q3) is at the 75th percentile (75% below, 25% above)\n",
    "\n",
    "<b>Quartiles can be used to calculate the Interquartile Range (IQR) - which can be used to handle outliers in your dataset.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a401565",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine the three quartiles of a set of data\n",
    "## A quantile is a series of values, or cut points, that divide a set of data into equal parts \n",
    "## A 'quartile' is a specical kind of quantile that divides the data into four equal parts\n",
    "\n",
    "df['Hours Worked'].quantile(.25) \n",
    "\n",
    "#Q1 = .25\n",
    "#Q2 = .50\n",
    "#Q3 = .75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70809067",
   "metadata": {},
   "source": [
    "#### All of the Above \n",
    "\n",
    "The describe function is perfect for outputting multiple descriptive statistics at once. This will save you multiple steps if you want to look at one or several quantitative variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c02bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the describe function to view multiple statistics at the same time\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7fc4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the describe function to isolate information for a single column\n",
    "\n",
    "df['Hours Worked'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fef3e31",
   "metadata": {},
   "source": [
    "# { Exercise 3 }\n",
    "\n",
    "    1. Using the pokemon dataset ('poke'), calculate the range for the HP column. \n",
    "    2. What is the mean and the standard deviation for the special attack (SpAtk) column?\n",
    "    3. For the Attack column, determine which value falls at the 80th percentile? Which value falls at the 15th percentile? For each of these values, write a single sentence describing what this means. \n",
    "    4. Calculate the second quartile (or the median) for the special defense (SpDef) column. Then, calculate the median of the same column using the method shown above. Are the values the same? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaf258a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aed6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1d602cd",
   "metadata": {},
   "source": [
    "## Handling and Removing Outliers\n",
    "\n",
    "***\n",
    "\n",
    "Outliers are data points that differ significantly from other data points. Outliers are an important feature of a dataset that should be identified and addressed because extreme values can influence the results of your statistics. \n",
    "\n",
    "   * In a sample of 5 students, their ages are 25, 22, 97, 23, 21 - 97 is an outlier because the value differs significantly from the remaining data.\n",
    "   * Without removing outlier, the mean is: 37.6 and the median is: 23\n",
    "   * When removing the outlier, the mean is: 22.75 and the median is: 22.5\n",
    "\n",
    "Determining which values are extreme can be challenging when you have a larger dataset. There are several methods that can be used to strategically determine which values are outliers, we will cover two separate methods below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SalaryData.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2bbacb",
   "metadata": {},
   "source": [
    "## Method 1 : Using z-scores to detect and remove outliers\n",
    "\n",
    "In statistics, the <font color=salmon><b>Empirical Rule</b></font> estimates how data, following a normal distribution, will spread around the mean. According to this rule, basically all data values will fall within 3 SD's above or below the mean. The Empirical Rule is also known as the <font color=salmon><b>68-95-99.7 Rule</b></font> because according to this rule, your data will typically fall into the following pattern:\n",
    "\n",
    "* 68% of the data falls within one SD of the mean\n",
    "\n",
    "* 95% of the data falls within two SD's of the mean\n",
    "\n",
    "* 99.7% of the data falls within three SD's of the mean\n",
    "\n",
    "<img src=\"SD Bell Curve.jpeg\">\n",
    "\n",
    "#### Empirical Rule Example:\n",
    "\n",
    "The average weight of an American man is 175 lbs with a SD of 10 lbs. According to the Empirical Rule, we can assume: \n",
    "\n",
    "* 68% of American men are between 165 and 185 lbs (or +/- 10 lbs from the mean, or 1 SD)\n",
    "* 95% of American men are between 155 and 195 lbs (or +/- 20 lbs from the mean, or 2 SD's)\n",
    "* 99.7% of American men are between 145 and 205 lbs (or +/- 30 lbs from the mean, or 3 SD's)\n",
    "* Typically, data values that fall outside of this range are considered outliers\n",
    "_______________________ \n",
    "A <font color=salmon><b>z-score</b></font>, also known as a standard score, measures the distance of a value from the mean. In other words, the z-score tells you how many SD's a given value is from the mean. Values that fall above the mean will have a positive (+) z-score, while values that fall below the mean will have a negative (-) z-score. Values that are far from the mean will be considered outliers. You can define a value as an outlier if the z-score greater than +/- 3. \n",
    "_______________________ \n",
    "\n",
    "#### Steps for Detecting and Removing Outliers with z-scores\n",
    "* Import the scipy library to make use of the z-score function\n",
    "* Calculate the z-score for each value within a specific column in your dataset\n",
    "* Transform the z-score to the absolute value of the z-score (number without the +/- sign; this will make our code simpler)\n",
    "* Add the z-scores to your dataset as a new column\n",
    "* Remove all rows that have a z-score greater than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44567cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a copy of your dataset to filter outliers\n",
    "dfz = df.copy()\n",
    "\n",
    "## Check original shape of the dataset\n",
    "print(dfz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61292858",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new column to contain the z-scores for the employee salary\n",
    "## Set the new column equal to the absolute value of the z-scores\n",
    "## To calculate z-score -- stats.zscore(data/column name)\n",
    "## To determine absolute value of z-score -- np.abs(data/function/options)\n",
    "\n",
    "dfz[\"zscore_salary\"] = np.abs(stats.zscore(dfz[\"Salary\"]))\n",
    "\n",
    "## Preview new column; optional\n",
    "dfz.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61532ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine the index locations for the rows with zscores that are greater than \"3\"\n",
    "z_outliers = dfz.loc[dfz[\"zscore_salary\"] > 3].index\n",
    "\n",
    "## Preview list of index values\n",
    "print(z_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efe5df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What information can we find at these index locations?\n",
    "\n",
    "dfz.iloc[[1, 28]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5df5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop rows with above index values\n",
    "dfz = dfz.drop(z_outliers)\n",
    "\n",
    "## Re-check the shape of the dataframe, how many rows were dropped?\n",
    "print(dfz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93017c0c",
   "metadata": {},
   "source": [
    "## Method 2 : Using the Interquartile Range (IQR) to detect and remove outliers\n",
    "\n",
    "The <font color=salmon><b>Interquartile Range (IQR)</b></font> is the difference between the first and third quartile in a set of data. The IQR can be considered where the bulk of the data values rest. IQR is calculated by the following equation: <B>IQR = Q3 - Q1</B>\n",
    "<img src=\"IQR.png\">\n",
    "_____________________\n",
    "\n",
    "The IQR can be used to create \"fences\" or cut-off values that determine which values fall outside of the acceptable data range. For example, we can calculate a lower-limit -- all values falling below this limit will be considered an outlier. The <b>1.5 Rule</b> is a commonly used method for determining the upper and lower cut-off limits. According to this rule, a value is considered an outlier if it falls:\n",
    "\n",
    "* ... below Q1 - (1.5 x IQR)\n",
    "\n",
    "* ... above Q3 + (1.5 x IQR)\n",
    "_____________________\n",
    "\n",
    "#### 1.5 Rule Example:\n",
    "\n",
    "A professor is tracking the number of absences for each of their students. They have compiled a list of the number of absences: \n",
    "\n",
    "    1, 3, [4], 6, 7, [7], 8, 8, [9], 22, 37 \n",
    "\n",
    "In this list of data, we can find the following values:\n",
    "\n",
    "* Q1 = 4\n",
    "* Q2 (median) = 7\n",
    "* Q3 = 9\n",
    "\n",
    "With these values, you can easily calculate the IQR:\n",
    "\n",
    "* <B>IQR</B> = Q3(9) - Q1(4)\n",
    "* <B>IQR</B> = 5\n",
    "\n",
    "Once you have the IQR, you can calculate the upper and lower limits for detecting outliers:\n",
    "\n",
    "* Upper Limit = Q3(9) + [1.5 * IQR(5)] = <b> 16.5 </b>\n",
    "* Lower Limit = Q1(4) - [1.5 * IQR(5)] = <b> -3.5 </b>\n",
    "\n",
    "Values that fall above the upper limit are outliers; values that fall below the lower limit are outliers\n",
    "_______________________ \n",
    "\n",
    "#### Steps for Detecting and Removing Outliers with IQR\n",
    "\n",
    "* Calculate quartiles\n",
    "* Calculate IQR\n",
    "* Determine upper and lower limits\n",
    "* Drop values less than the lower and/or greater than the upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8694f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a copy of original dataset\n",
    "dfq = df.copy()\n",
    "\n",
    "## Check original shape of the dataset\n",
    "dfq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84c2fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate quartiles\n",
    "q1 = dfq[\"Salary\"].quantile(.25)\n",
    "q3 = dfq[\"Salary\"].quantile(.75)\n",
    "\n",
    "print(\"Q1:\", q1)\n",
    "print(\"Q3:\", q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b36fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the IQR\n",
    "iqr = q3 - q1\n",
    "\n",
    "print(\"IQR:\", iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fabd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine outlier fences \n",
    "top = q3 + (iqr * 1.5)\n",
    "bottom = q1 - (iqr * 1.5)\n",
    "\n",
    "\n",
    "print(\"Upper Limit:\", top)\n",
    "print(\"Lower Limit:\", bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3040926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine the index locations for rows that fall outside of outlier fences\n",
    "\n",
    "iqr_outliers = dfq.loc[(dfq['Salary'] > top) | (dfq['Salary'] < bottom)].index\n",
    "\n",
    "print(\"INDEX VALUES:\", iqr_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d819df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## what values can we find at these index locations?\n",
    "\n",
    "dfq.iloc[[1, 12, 28]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop rows with above index values\n",
    "dfq = dfq.drop(iqr_outliers)\n",
    "\n",
    "## Re-check the shape of the dataframe, how many rows were dropped?\n",
    "print(dfq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e148156",
   "metadata": {},
   "source": [
    "# { Module 10 Homework }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736faa7d",
   "metadata": {},
   "source": [
    "1. Import the \"babies.xlsx\" dataset. See below for information on the columns:\n",
    "\n",
    "    * bwt - birth weight of newborn baby\n",
    "    * gestation\t- gestation length (weeks)\n",
    "    * parity - previously pregnant (0 = no; 1 = yes)\n",
    "    * age - age of mother\n",
    "    * height - height of mother (inches)\t\n",
    "    * weight - weight of mother (pounds)\n",
    "    * smoke - smoking status of mother (0 = nonsmoker; 1 = smoker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ef2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dt = pd.read_excel(\"babies.xlsx\")\n",
    "\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04bfa22",
   "metadata": {},
   "source": [
    "2. Preview the first few rows of the dataset. Complete the following checks for your dataset:\n",
    "\n",
    "    * output the summary information for the dataset, what types of variables make up this dataset?\n",
    "    * is there any missing data in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86263ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e181bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.isnull().sum()\n",
    "#there are some missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a9f160",
   "metadata": {},
   "source": [
    "3. Handle the missing data in the dataset -- there isn't much, so we can drop all the rows that have at least one missing value. How many rows were dropped from the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b362c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.dropna(inplace = True)\n",
    "\n",
    "## check the changes\n",
    "\n",
    "dt.info()\n",
    "\n",
    "#64 rows were dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e6e31",
   "metadata": {},
   "source": [
    "4. There are two qualitative variables in this dataset. What are they? How do you know they are qualitative variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52b1b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.head()\n",
    "\n",
    "#Parity and smoke: they have categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee4ec8",
   "metadata": {},
   "source": [
    "5. Replace the values in the qualitative variables with meaningful labels that describe the different groups. Use any method you've learned in previous modules to complete this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8abc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"parity\"].replace([0, 1], [\"no\", \"yes\"], inplace = True)#  [0.0, \"no\"], [1.0, \"yes\"])#inplace = True)\n",
    "\n",
    "## for parity\n",
    "\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05657527",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"smoke\"].replace([0.0, 1.0], [\"no\", \"yes\"], inplace = True)#  [0.0, \"no\"], [1.0, \"yes\"])#inplace = True)\n",
    "\n",
    "## check work\n",
    "\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6974eb82",
   "metadata": {},
   "source": [
    "6. Before we move forward with any statistics, let's identify and remove any outliers from the dataset. Using the IQR method, search for outliers in the 5 numeric variables. This will take some time and organization, be careful with your code! Make sure you keep track of how many rows/outliers are removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['bwt'].quantile(.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['gestation'].quantile(.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05904ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['age'].quantile(.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b59a17",
   "metadata": {},
   "source": [
    "7. Describe the characteristics of your qualitative variables by doing the following:\n",
    "\n",
    "    * Determine the frequencies of each group within each categorical variable. Which groups have the highest frequency?\n",
    "    * Determine the relative frequencies of each group within each categorical variable. Which groups have the highest relative frequencies?\n",
    "    * Create a crosstab table using both the categorical variables in your dataset. How many mothers are smokers who have been pregnant before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154871ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"parity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d5497",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"smoke\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53db050",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"parity\"].value_counts(normalize=True)\n",
    "#relative frequency of parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819fcf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"smoke\"].value_counts(normalize=True)\n",
    "#relative frequency of smoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dt[\"smoke\"], dt[\"parity\"], margins=False, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfac25c7",
   "metadata": {},
   "source": [
    "8. Describe the Measures of Central Tendency (mean, median, mode) of the numeric variables in the dataset. Calculate the mean, median, and mode for all 5 numeric variables. For each median and mode, describe the following:\n",
    "\n",
    "    * What does the median value tell you about the data?\n",
    "    * What does the mode value tell you about the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994afbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"bwt\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924f540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"gestation\"].median()\n",
    "#the middle value is 280.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec816ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"age\"].mode()\n",
    "#age 23.0 appears morethan once in the datasheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a47b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6238626d",
   "metadata": {},
   "source": [
    "9. Describe the Measures of Variability of the numeric variables in the dataset. Calculate the range, standard deviation, and 85th percentile for all 5 numeric variables. Answer the following questions:\n",
    "\n",
    "    * Which column has the largest range? Which has the smallest? What does this mean?\n",
    "    * Which column has the largest standard deviation? Which has the smallest? What does this tell you about those variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c06a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "bwt_range = dt['bwt'].max() - dt['bwt'].min()\n",
    "\n",
    "print(bwt_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e388f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gestation_range = dt['gestation'].max() - dt['gestation'].min()\n",
    "\n",
    "print(gestation_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86295efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_range = dt['age'].max() - dt['age'].min()\n",
    "\n",
    "print(age_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e64fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_range = dt['height'].max() - dt['height'].min()\n",
    "\n",
    "print(height_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_range = dt['weight'].max() - dt['weight'].min()\n",
    "\n",
    "print(weight_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight has the largest range\n",
    "#height has the smallest range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"weight\"].std()\n",
    "#standrad deviation of weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154245a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(dt['weight'], 85)\n",
    "#85th percentile of weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d163df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
